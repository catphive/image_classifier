\documentclass[11pt]{article}
\title{CSE 576 Project 2: Feature Detection, Description and Matching}
\author{Brendan Miller}
\usepackage{multirow,amsmath}
\usepackage{graphicx}
\usepackage{fancyvrb}
\usepackage{color}
\usepackage{amsfonts}
%\usepackage{hyperref}
\usepackage{longtable}
\begin{document}

\maketitle
\section{Introduction}

This project recognizes images that contain certain classes of
objects. To do this I use the generative/descriminative framework
discussed in Yi Li\cite{gendesc}.

Whereas Li's paper used features extracted from clustered abstract
regions such as color and texture, this project also uses descriptors
extracted from keypoints. Specifically, the keypoints and descriptors
generated by SIFT.

Motivation behind the project

Objective of the project

\section{Related work}

NOTE: talk about generative descriminative.

This project is primarily based on \emph{A Generative/Discriminative
  Learning Algorithm for Image Classification} by Yi
Li\cite{gendesc}. Li's generative/discriminative classifier framework
works in two stages.

First, features are extracted from a training set of positive
examples. From this set of features, the expectation maximization
algorithm is used to create a gaussian mixture model of the
distribution of the features.

For an object $o$ and a feature type $a$ the probability of a
particular feature vector $X^a$ appearing can be calculated from the
gaussian mixture model as
\begin{equation*}
  P(X^a|o) = \sum_{m=1}^{M^a} w^a_m N(X^a; \mu^a_m, \Sigma^a_m)
\end{equation*}
where $M^a$ is the number of clusters in the mixture model for feature
$a$. For the $m$th gaussian of feature $a$ $w^a_m$ is the weight,
$\mu^a_m$ is the mean, and $\Sigma^a_m$ is the covariance matrix.

In the discriminative step, both positive and negative examples are
used to train a classifier, in this case a pretty standard 3 layer
neural network.

For each image the maximum of the joint probabilities of each feature
in the image and each component gaussian for that feature type is
calculated like so:



Relevant literature

Similar methods, and what are their differences to your method

\section{Your method}

Describe your method and algorithms


NOTE: talk about descriptors used.

\section{Experiments and results}

Describe the datasets that you used

Evaluation criteria

Performance evaluation:

Analysis of the performance

Use images, tables and graphs to help describe your results

Classification accuracy using both color and SIFT features:

\begin{tabular}{| l | l | l | l |}
  \hline
  Image Type & Accuracy     & False Positives    & False Negatives \\
  Cars      & 0.94  & 0.035 & 0.025 \\
  Planes    & 0.78  & 0.11  & 0.11  \\
  Faces     & 0.9   & 0.055 & 0.045 \\
  Bikes     & 0.805 & 0.08  & 0.115 \\
  \hline
\end{tabular}


\section{5. Future work}

TODO:Possible future  extensions to the project.

The original descrimitive generative paper also included texture and
structural features, so an obvious extension would be to include those
features as well.

Beyond that, finding higher performance means of extracting features
similar to the existing ones would mak it practical to include more
features in the classifier.

In particular, since running k means on input images to perform
classification is somewhat time consuming for real time applications,
more efficient means of extracting color features might be tried. For
instance, a color histogram might be formed, and the peak bins of the
histogram used as features.

Even if the more efficient features are less predictive individually,
since they allow time for additional features to be computed, the
classifier overall could have better performance.

An alternative approach might be to extract different feature classes
simultaniously in different threads.


\section{Summary and conclusion}

\begin{thebibliography}{9}

\bibitem{gendesc}
  Y. Li, L. G. Shaprio, and J. Bilmes
  \emph{A Generative/Discriminative Learning Algorithm for Image Classification}.
  Department of Computer Science and Engineering,
  Department of Electrical Engineering,
  University of Washington

\end{thebibliography}

\end{document}
